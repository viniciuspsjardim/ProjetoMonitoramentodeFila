# Healthcare Operations Data & AI Platform (AWS Serverless)

Plataforma de dados e IA para efici√™ncia operacional em sa√∫de, focada em previs√£o de lota√ß√£o e tempo de espera. Arquitetura Serverless na AWS com ETL robusto e m√≥dulos de IA generativa.

## üèó Arquitetura

A solu√ß√£o utiliza uma arquitetura de Data Lake em camadas (Bronze/Silver/Gold) orquestrada por Step Functions.

```mermaid
graph TD
    Gen[Synthetic Data] -->|Raw| S3[S3 Data Lake]
    S3 -->|Trigger| SF[Step Functions Orchestrator]
    SF --> Glue[AWS Glue ETL]
    Glue -->|Parquet| Athena[Amazon Athena]
    Glue -->|Train/Predict| ML[ML Models]
    ML -->|Inference| Gold[S3 Gold]
    Gold -->|Query| API[FastAPI / BI]
    
    subgraph Advanced AI
        LambdaClass[Lambda Classification]
        LambdaRAG[Lambda RAG KB]
    end
```

## üìö Decis√µes de Arquitetura (Guia de Estudo)

Este projeto foi desenhado para demonstrar uma arquitetura de dados moderna, escal√°vel e de baixo custo operacional (Serverless). Abaixo, a explica√ß√£o do "porqu√™" de cada componente:

### 1. Data Lakehouse (S3 + Athena)
*   **Por que S3?** Diferente de bancos tradicionais, o S3 separa armazenamento de processamento. √â infinitamente escal√°vel e muito barato.
*   **Camadas (Medallion Architecture)**:
    *   **Bronze (Raw)**: C√≥pia fiel da origem. Se errarmos a transforma√ß√£o, podemos sempre reprocessar a partir daqui.
    *   **Silver (Clean)**: Dados limpos, tipados e deduplicados. Aqui aplicamos Schemas.
    *   **Gold (Curated)**: Dados agregados (KPIs) prontos para consumo.
*   **Por que Athena?** Permite rodar SQL diretamente nos arquivos do S3 (Serverless). Evita o custo de manter um Data Warehouse (como Redshift) ligado 24/7 para volumes pequenos/m√©dios.

### 2. Processamento (AWS Glue)
*   **Spark vs Python Shell**:
    *   Usamos **Glue PySpark** para transforma√ß√µes pesadas (Silver/Gold) porque o Spark distribui o processamento em v√°rios n√≥s (cluster).
    *   Usamos **Glue Python Shell** para tarefas leves (Ingest√£o, Infer√™ncia ML simples) porque custa uma fra√ß√£o do pre√ßo do Spark e liga muito mais r√°pido.

### 3. Orquestra√ß√£o (Step Functions vs Airflow)
*   Para este MVP, escolhemos **Step Functions** porque √© totalmente nativo AWS e Serverless.
*   **Airflow (MWAA)** seria excelente para fluxos muito complexos, mas exige que voc√™ pague por servidores "ligados" o tempo todo. O Step Functions cobra por transi√ß√£o de estado, sendo ideal para pipelines event-driven.

### 4. Machine Learning & IA
*   **Scikit-Learn no Glue**: Para modelos tabulares leves, rodar dentro do pr√≥prio ETL simplifica a infraestrutura (sem necessidade de SageMaker Endpoints caros para infer√™ncia batch).
*   **OpenAI + Lambda**: Delegamos a intelig√™ncia de NLP (texto) para LLMs via API. O Lambda atua apenas como um "proxy" leve, mantendo o custo muito baixo (pagamento por milissegundo de execu√ß√£o).

## üöÄ Como Executar

### Pr√©-requisitos
- Python 3.9+
- Conta AWS configurada (AWS CLI)
- Terraform (para deploy da infraestrutura)
- OpenAI API Key

### 1. Instala√ß√£o Local (Simula√ß√£o)
Para rodar o pipeline completo localmente (sem AWS):

```bash
# Criar ambiente virtual
python -m venv .venv
.venv\Scripts\Activate.ps1

# Instalar depend√™ncias
pip install -r requirements.txt

# Executar Pipeline Local
python run_local_pipeline.py
```

Isso ir√° gerar uma pasta `data_local/` com os arquivos parquet das camadas Bronze, Silver e Gold, al√©m de executar o treino e infer√™ncia do modelo.

### 2. Deploy na AWS (Infraestrutura)
```bash
cd infra
terraform init
terraform apply -var="openai_api_key=sk-..."
```
Isso criar√°: S3 Buckets, Glue Jobs, Step Functions, Lambdas e Secrets.

### 3. Deploy do C√≥digo (ETL & AI)
Os scripts em `src/` devem ser zipados e enviados para o S3 de artefatos (gerenciado pelo Terraform/CI CD pipeline).

## üìÇ Estrutura do Projeto
- `infra/`: C√≥digo Terraform (IaC).
- `src/data_gen/`: Gerador de dados sint√©ticos.
- `src/etl/`: Scripts Glue (Ingest√£o, Limpeza, Qualidade).
- `src/ml/`: Scripts de Treino e Infer√™ncia.
- `src/ai/`: Lambdas de IA Avan√ßada (Classifica√ß√£o, RAG).
- `src/ddl/`: Scripts SQL para Athena.
- `runbook.md`: Guia de Opera√ß√£o e Resposta a Incidentes.

## üìñ Documenta√ß√£o Adicional
- [Runbook Operacional](./runbook.md)
- [Dicion√°rio de Dados](./data_dictionary.md) (Artifact)

## üí° Conceitos de Dados & Nomenclatura

Para facilitar consultas futuras e expans√°o, adotamos conven√ß√µes de Engenharia de Dados e MLOps. Abaixo, o significado dos principais campos:

### `sector_id` (Identificador da Entidade)
*   **Significado**: ID do Setor Hospitalar (ex: Emergency, Pediatrics).
*   **Por que "_id"?**: O sufixo `_id` indica que campo √© uma chave de busca ou agrupamento (Foreign Key), facilitando joins com tabelas de dimens√£o (ex: para pegar o nome do gerente do setor).

### `prediction_ts` (Timestamp de Refer√™ncia)
*   **Significado**: A data e hora exata em que o modelo **executou** a previs√£o.
*   **Import√¢ncia**: Diferente do "target time" (para *quando* √© a previs√£o), este campo permite auditar a performance do modelo ao longo do tempo (Model Monitoring). Permite responder: "O que o modelo achava que ia acontecer h√° 3 horas atr√°s?".

### `predicted_arrivals_h1` (Target + Horizonte)
*   **Estrutura**: `[tipo]_[metrica]_[horizonte]`
    *   **predicted**: Valor estimado pelo modelo.
    *   **arrivals**: A m√©trica de neg√≥cio.
    *   **h1**: Horizonte de 1 hora.
*   **Expans√£o**: Para adicionar previs√µes de 4 ou 24 horas, basta criar colunas `predicted_arrivals_h4` e `predicted_arrivals_h24`. O formato *wide* facilita a cria√ß√£o de dashboards comparativos.

## üîÆ Possibilidades de Expans√£o (Estudo)

1.  **Dashboards de BI (Amazon QuickSight / PowerBI)**:
    *   Conectar ao Athena e criar gr√°ficos de **Previsto vs Real** usando `prediction_ts` para alinhar as janelas de tempo.
2.  **Monitoramento de Model Drift**:
    *   Criar um Job Glue que compara a distribui√ß√£o estat√≠stica de `predicted_arrivals_h1` da semana passada com a atual para detectar anomalias.
3.  **Feature Store**:
    *   Evoluir a tabela `silver` para uma Feature Store dedicada (ex: AWS Feature Store) para reutilizar features de `rolling_avg` em outros modelos.
